#!/bin/bash
# Copyright (C) 2010 Ion Torrent Systems, Inc. All Rights Reserved
set -e
#set -x

LOGFILE=/tmp/ion-dbreports_install.log
exec > >(tee "$LOGFILE") 2>&1

echo "postinst $@"

unset CELERY_LOADER

case "$1" in
    configure)

    KEY_FILE=/var/spool/ion/key
    if [ ! -f $KEY_FILE ]; then
        cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 256 | head -n 1 > $KEY_FILE
        chown www-data:www-data $KEY_FILE
    fi
    # updated all instances of the key file to this permission level as per TS-14740
    chmod 0440 $KEY_FILE

    # create or update the off-cycle release source url
    if [ -f /etc/apt/sources.list.d/iontorrent-offcycle.list ]; then
        sed -i "s/deb http:\/\/ionupdates.com\/updates\/software\/offcycle\/[^0-9.]*\([0-9.]*\).*/deb http:\/\/ionupdates.com\/updates\/software\/offcycle\/@TS_MAJOR@.@TS_MINOR@.@TS_RELEASE@\/ @LSB_RELEASE_CODENAME@\//" /etc/apt/sources.list.d/iontorrent-offcycle.list
    else
        echo "deb http://ionupdates.com/updates/software/offcycle/@TS_MAJOR@.@TS_MINOR@.@TS_RELEASE@/ @LSB_RELEASE_CODENAME@/" > /etc/apt/sources.list.d/iontorrent-offcycle.list
    fi

    #MegaCli64 library support
    if [ -e /lib/libsysfs.so.2.0.1 ]; then
        if [ ! -h /usr/lib64/libsysfs.so.2.0.2 ]; then
            ln -s /lib/libsysfs.so.2.0.1 /usr/lib64/libsysfs.so.2.0.2 || true
        fi
    fi

    chmod ugo+x @ION_INSTALL_PREFIX@/iondb/bin/*

    DJANGOADMIN=@ION_INSTALL_PREFIX@/manage.py
    chmod ugo+x ${DJANGOADMIN}

    ## Early trigger of python support
    #  This normally runs at the end of an apt-get run
    #  But if modules we need are installed in the same pass various tasks fail due to missing packages,
    #  because they aren't symlinked yet.
    if which update-python-modules; then
        update-python-modules --post-install
    fi

    ## Precompile / recompile python packages
    #/usr/bin/python -O -m compileall "@ION_INSTALL_PREFIX@/iondb/"
    (/usr/bin/python -m compileall -q -f "@ION_INSTALL_PREFIX@/iondb/" || /bin/true)

    #---											---#
    #---	Genome Directories Permissions, etc.	---#
    #---	head node only; /results shared out		---#
    #---											---#
    #will this always be results?
    mkdir -p /results/referenceLibrary/temp
    mkdir -p /results/referenceLibrary/tmap-f1
    mkdir -p /results/referenceLibrary/tmap-f2
    mkdir -p /results/referenceLibrary/tmap-f3
    mkdir -p /results/referenceLibrary/disabled/tmap-f1
    mkdir -p /results/referenceLibrary/disabled/tmap-f2
    mkdir -p /results/referenceLibrary/disabled/tmap-f3
    mkdir -p /results/referenceLibrary/TestFragment
    chmod -R 777 /results/referenceLibrary/temp
    chmod -R 777 /results/referenceLibrary/tmap-f1
    chmod -R 777 /results/referenceLibrary/tmap-f2
    chmod -R 777 /results/referenceLibrary/tmap-f3
    chmod -R 777 /results/referenceLibrary/disabled
    chmod -R 777 /results/referenceLibrary/TestFragment

    chown -R www-data:www-data /results/referenceLibrary/TestFragment

    #make pluginMedia dir
    mkdir -p /results/pluginMedia
    chmod -R 777 /results/pluginMedia

    # make the celeryd pid run directory with permissions
    mkdir -p /var/run/celery
    chmod ugo+rw /var/run/celery

    #	------------------------------------------
    #	Replace existing httpd.conf
    #	------------------------------------------
    # If exists and non-empty, use numbered backups - old.1, old.2, ...
    if [ -s /etc/apache2/httpd.conf ]; then
        mv -v --backup=numbered /etc/apache2/httpd.conf /etc/apache2/httpd.conf.old
    fi
    # Default Ubuntu file is empty. Config now in /etc/apache2/conf.d/
    touch /etc/apache2/httpd.conf

    # Get PROXY variables into apache environment
    if ! grep -q 'ION_APACHE_PROXY_ENV' /etc/apache2/envvars; then
        # NOTE: Use of leading TABS below is intended. Do not replace with spaces!
        cat >> /etc/apache2/envvars <<-ENDOFAPACHEENV
		# ION_APACHE_PROXY_ENV Import Proxy Server settings from /etc/environment
		if [ -e "/etc/environment" ]; then
		    . "/etc/environment"
		    if [ ! -z "${http_proxy}" ]; then
		        if [ -z "${HTTP_PROXY}" ]; then
		            HTTP_PROXY="${http_proxy}"
		        fi
		        if [ -z "${no_proxy}" ]; then
		            # Set default value for no_proxy if missing
		            no_proxy="localhost,127.0.0.1"
		        fi
		        export http_proxy no_proxy HTTP_PROXY
		    fi
		fi
ENDOFAPACHEENV

    fi

    #create hard-coded credentials to handle <Location "/basicauthlogout"> within torrent-server.in
    htpasswd -b -c /etc/apache2/users logout logout

    # Enable required apache modules
    /usr/sbin/a2enmod wsgi headers ssl setenvif deflate filter expires rewrite include
    # Note: wsgi and ssl are non-core and installed separately. Check depends list

    # Switch to the torrent-server apache vhost - remove stock ubuntu vhosts
    /usr/sbin/a2dissite 000-default || true
    /usr/sbin/a2dissite default || true
    /usr/sbin/a2dissite default-ssl || true

    # Some machines have files instead of symlinks here, which a2ensite and a2dissite choke on.
    /bin/rm -f /etc/apache2/sites-enabled/default /etc/apache2/sites-enabled/default-ssl
    /bin/rm -f /etc/apache2/sites-enabled/torrent-server /etc/apache2/sites-enabled/torrent-server-ssl

    # Enable Torrent Suite vhosts - http and https
    /usr/sbin/a2ensite torrent-server.conf
    /usr/sbin/a2ensite torrent-server-ssl.conf

    # Apache 2.4 on Ubuntu 14.04
    /usr/sbin/a2enconf h5bp-server.conf
    /usr/sbin/a2enconf torrent-server-config.conf

    # apache2 restarted by invoke-rc.d command below

    #	------------------------------------------
    #	Additional apache2 related configurations
    #	------------------------------------------
    mkdir -p /results/analysis/output
    mkdir -p /results/analysis/output/disabled
    mkdir -p /results/chef_logs
    mkdir -p /results/OT
    chown www-data.www-data /results/analysis/output
    chown www-data.www-data /results/analysis/output/disabled
    chown www-data.www-data /results/chef_logs
    chown www-data.www-data /results/OT
    chmod a+w /results/chef_logs
    chmod a+w /results/OT

    # some systems export a different /results for reports
    # don't want to squash that link.
    if [ ! -h /var/www/output ]; then
        # link does not exist...but it might be a file or dir.
        ln -s -f /results/analysis/output /var/www/output
    fi

    rm -f /var/www/chef_logs
    if [ -d /rawdata ]; then
        # link does not exist...but it might be a file or dir.
        ln -s -f /rawdata/chef_logs /var/www/chef_logs
    else
        ln -s -f /results/chef_logs /var/www/chef_logs
    fi
    if [ ! -h /var/www/ot_logs ]; then
        # link does not exist...but it might be a file or dir.
        ln -s -f /results/OT /var/www/ot_logs
    fi
    # /var/www/plugins replaces pluginMedia
    if [ ! -h /var/www/plugins ]; then
        # link does not exist...but it might be a file or dir.
        ln -s -f /results/plugins /var/www/plugins
    fi

    # create the plugins directory
    mkdir -p /results/plugins
    chmod 777 /results/plugins

    # create the scratch directory
    mkdir -p /results/plugins/scratch
    chmod 777 /results/plugins/scratch

    # create a plugin archive directory
    mkdir -p /results/plugins/archive
    chmod 777 /results/plugins/archive

    # Note, was a symlink, now a folder
    [ ! -d /var/www/media ] && rm -f /var/www/media
    mkdir -p /var/www/media
    chown www-data:www-data /var/www/media

    # Populated by collectstatic now
    #ln -s -f @ION_INSTALL_PREFIX@/iondb/media /var/www/site_media
    [ ! -d /var/www/site_media ] && rm -f /var/www/site_media
    mkdir -p /var/www/site_media

    # Delete broken, circular symlinks that used to live here. TS-7013
    # Must be cleaned up or collectstatic hangs
    [ -h "@ION_INSTALL_PREFIX@/iondb/media/media" ] && rm -f "@ION_INSTALL_PREFIX@/iondb/media/media"
    [ -h /var/www/site_media/media ] && rm -f /var/www/site_media/media
    # Delete broken symlinks in media folder - stem from bad collectstatic runs
    find -P "@ION_INSTALL_PREFIX@/iondb/media/" -type l -delete
    find -P "/var/www/site_media/" -type l -delete

    #symLink for plugin media
    rm -f /var/www/pluginMedia
    ln -s /results/pluginMedia /var/www/pluginMedia

    rm -f /results/analysis/output/tmap-*
    ln -s -f /results/referenceLibrary/tmap-* /results/analysis/output/

    rm -f /results/analysis/output/disabled/tmap-*
    ln -s -f /results/referenceLibrary/disabled/tmap-* /results/analysis/output/disabled

    # ------------------------------------------
    # Create ionian user if it doesn't exist: user is needed to initialize
    # ownership of log files below
    # ------------------------------------------
    if ! id -u ionian; then
        # NOTE: non-unique was added as result of TS-11113
        groupadd ionian --gid=1100 --system
        useradd --gid ionian --uid=1100 --non-unique --system ionian
    fi

    #---									        				---#
    #---	Configure runlevels to start the Ion daemons at boot	---#
    #---										    				---#
    DAEMONS=(
        ionCrawler
        ionJobServer
        ionPlugin
        )
    for DAEMON in ${DAEMONS[@]}; do
        # Need to fix the start/kill priority for the daemons
        # If any priority is K97, reset it
        if [ `find /etc/rc?.d -name \*${DAEMON}|grep -c K97` -gt 0 ]; then
            update-rc.d -f ${DAEMON} remove
        fi
        update-rc.d ${DAEMON} defaults 97 03
    done

    # ------------------------------------------
    # Create directory for logging
    # ------------------------------------------
    mkdir -p /var/log/ion
    chown www-data.www-data /var/log/ion
    chmod a+w /var/log/ion
    chown www-data.www-data /var/spool/ion  # created in CMakeLists.txt
    chmod g+w /var/spool/ion    # set in CMakeLists.txt but want to be certain

    # touchy code
    for log_file in django.log crawl.log ionPlugin.log celery_plugins.log data_management.log
    do
        touch /var/log/ion/$log_file
        chown :www-data /var/log/ion/$log_file
        chmod g+rw /var/log/ion/$log_file
    done
    chown ionian:www-data /var/log/ion/django.log
    chown ionian:www-data /var/log/ion/celery_plugins.log
    chown ionian:www-data /var/log/ion/ionPlugin.log
    chown root:www-data /var/log/ion/data_management.log

    chown -R www-data:www-data @ION_INSTALL_PREFIX@/iondb

    #--------------------------------------------------#
    #---	Remove possible stale ion packages      ---#
    #--------------------------------------------------#
    if [ -d @PYTHON_LOCAL_SITE_PACKAGES@/ion ]; then
        rm -rf @PYTHON_LOCAL_SITE_PACKAGES@/ion
    fi

    # stop the dependent services
    if [ -f "/etc/init.d/tomcat7" ]; then
        invoke-rc.d tomcat7 stop
    fi

    invoke-rc.d apache2 stop

    # we are going to have to do an explicit startup of the postgresql system to make sure it's up and going
    # before we attempt to setup the database environment
    invoke-rc.d postgresql start

    # doing an explicit wait to make sure that PG is initialized from the previous command
    sleep 5

    # Setup python and database environment
    (
        cd @ION_INSTALL_PREFIX@/iondb/

        # Create ionadmin if a superuser does not exist
        /usr/bin/python ./bin/initsprusr.py

        # Legacy DB migration - Updates an existing database schema to 2.2
        /usr/bin/python ./bin/migrate.py

        # Django South DB migration - applies changes in rundb/migrations/
        /usr/bin/python ${DJANGOADMIN} migrate --all --ignore-ghost-migrations --noinput

        # Print current db migration state for diagnostic purposes
        /usr/bin/python ${DJANGOADMIN} migrate --list --noinput

        # Full syncdb to create ContentTypes and Permissions
        /usr/bin/python ${DJANGOADMIN} syncdb --noinput --all

        # Backfill tastypie API keys
        /usr/bin/python ${DJANGOADMIN} backfill_api_keys

        # Loads Test Fragment entries into database
        #/usr/bin/python ${DJANGOADMIN} loaddata template_init.json
        /usr/bin/python ./bin/install_testfragments.py rundb/fixtures/template_init.json

        # Collect static files (eg. admin pages css/js).
        # TS-9967 Purging content with clear instead of keeping old md5 hashed versions
        /usr/bin/python ${DJANGOADMIN} collectstatic --verbosity=0 --noinput --link --clear

        # Creates default report templates with site-specific content
        /usr/bin/python ./bin/base_template.py
        /bin/chown www-data:www-data @ION_INSTALL_PREFIX@/iondb/templates/rundb/php_base.html

        # Updates existing database entries
        # THIS HAS TO HAPPEN AFTER THE PHP_BASE.HTML FILE IS PUT INTO PLACE DO NOT MOVE
        /usr/bin/python ./bin/install_script.py

		# Load barcode kits to database if needed
		echo "Going to add barcode kits if needed..."
		/usr/bin/python ./bin/add_barcodes.py "Ion SingleSeq Barcode set 1-24"  rundb/fixtures/barcodes/SingleSeq_1-24.csv
		/usr/bin/python ./bin/add_barcodes.py "Ion SingleSeq Barcode set 1-96"  rundb/fixtures/barcodes/SingleSeq_1-96.csv OVERRIDE
		/usr/bin/python ./bin/add_barcodes.py "TagSequencing"  rundb/fixtures/barcodes/TagSequencing.csv
						
        # Loads system templates to database if needed
        echo "Going to add or update system plan templates if needed..."
        /usr/bin/python ./bin/add_or_update_systemPlanTemplates.py

        # Loads DMFileSet entries into database
        /usr/bin/python ./bin/install_dmfilesets.py

        cd -
    )

    echo "NODENAME=rabbit@localhost" > /etc/rabbitmq/rabbitmq-env.conf
    cat > /etc/rabbitmq/rabbitmq.config <<EOF
[
    {rabbit, [{disk_free_limit, 110000000}]}
].
EOF
    if ! service rabbitmq-server restart; then
        service rabbitmq-server stop
        pgrep -u rabbitmq|xargs kill || true #ensure all rabbitmq pid are down
        rm -rf /var/lib/rabbitmq/mnesia/rabbit@localhost || true
        service rabbitmq-server start
    fi

    # -------------------------------------------------------------------------
    # Configure Celery's RabbitMQ user, vhost, and permission state
    # -------------------------------------------------------------------------
    if [[ ! `rabbitmqctl list_users|grep ^ion` ]]; then
        echo "Adding RabbitMQ user 'ion'"
        rabbitmqctl add_user ion ionadmin
    fi
    if [[ ! `rabbitmqctl list_vhosts|grep ^ion` ]]; then
        echo "Adding RabbitMQ vhost 'ion' and setting permissions for user 'ion'"
        rabbitmqctl add_vhost ion
        rabbitmqctl set_permissions -p ion ion ".*" ".*" ".*"
    fi

    if [ -f "/etc/init.d/tomcat7" ]; then
        invoke-rc.d tomcat7 start
    fi
    invoke-rc.d apache2 start
    invoke-rc.d celeryd start
    invoke-rc.d celerybeat start
    service DjangoFTP start

    #load the references for a first time
    (wget -q -O /dev/null http://localhost/configure/references/ > /dev/null) || \
        echo "Loading references failed."    
    
    #load the config page to update plugins and publishers
    python -c 'import iondb.bin.djangoinit, iondb.plugins.tasks as tasks; tasks.add_remove_plugins.apply_async(countdown=60)'

    # Rescan size and inode count for PluginResults
    python -c 'import iondb.bin.djangoinit, iondb.plugins.tasks as tasks; tasks.backfill_pluginresult_diskusage.apply_async(countdown=60)'
    # Update status values for plugins
    python -c 'import iondb.bin.djangoinit, iondb.plugins.tasks as tasks; tasks.cleanup_pluginresult_state.apply_async(countdown=60)'

    # Check whether or not we're online for CSA support upload
    python -c 'import iondb.bin.djangoinit, iondb.rundb.data.data_export as tasks; tasks.poll_support_site.apply_async(countdown=61)'

    #TS-6081: Create DMFileStat objs for existing Results objs without them.
    echo -n "Migrating to new Data Management..."
    python -c 'import iondb.bin.djangoinit, iondb.rundb.data.data_management as dm; dm.backfill_create_dmfilestat()'
    echo "done"

    # Now that prerequisite tasks have been run or scheduled, restart crawler.
    invoke-rc.d ionJobServer restart
    invoke-rc.d ionPlugin restart
    invoke-rc.d ionCrawler restart
    invoke-rc.d avahi-daemon restart

    # fire off the grooming script
    /opt/ion/iondb/bin/grooming.py
    ;;
esac

exit 0
